{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3U6d40fLBvw"
      },
      "outputs": [],
      "source": [
        "## Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.util import ngrams\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud\n",
        "import unicodedata\n",
        "import stop_words\n",
        "import spacy\n",
        "from spacy.lang.en import stop_words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Corpus\n",
        "df = pd.read_csv('wine.csv')\n",
        "print(df.head(2))"
      ],
      "metadata": {
        "id": "5-fc0wJ-LiZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean Data\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "sqyXd9x6LieD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Data\n",
        "df['notes'] = df['notes'].apply(lambda x: unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore'))\n",
        "df['notes'] = df['notes'].str.lower()\n",
        "df['notes'] = df['notes'].str.replace(r'[^\\w\\s]','', regex = True)\n",
        "df['notes'] = df['notes'].str.replace('\\d+', '', regex=True)\n",
        "stop_words = stop_words.STOP_WORDS\n",
        "df['notes'] = df['notes'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "df['notes'].head(5)"
      ],
      "metadata": {
        "id": "vesHpmNqLiht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize Text\n",
        "documents = list(df['notes'])\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorized_documents = vectorizer.fit_transform(documents)\n",
        "vectorized_documents"
      ],
      "metadata": {
        "id": "_dO1fj_ILiky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimesions Reduction (Two Dimesnions)\n",
        "pca = PCA(n_components=2)\n",
        "reduced_data = pca.fit_transform(vectorized_documents.toarray())"
      ],
      "metadata": {
        "id": "6naTOmQyLinb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cluster using k-means\n",
        "\n",
        "# cluster the documents using k-means\n",
        "num_clusters = 3\n",
        "kmeans = KMeans(n_clusters=num_clusters, n_init=5,\n",
        "                max_iter=500, random_state=42)\n",
        "kmeans.fit(vectorized_documents)\n",
        "\n",
        "# create a dataframe to store the results\n",
        "results = pd.DataFrame()\n",
        "results['document'] = documents\n",
        "results['cluster'] = kmeans.labels_\n",
        "\n",
        "# print the results\n",
        "print(results.sample(50))"
      ],
      "metadata": {
        "id": "Y9-5I02mLiqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word cloud (Label clusters)\n",
        "def wordcloud_clusters(model, vectors, features, no_top_words=40):\n",
        "    for cluster in np.unique(model.labels_):\n",
        "        size = {}\n",
        "        words = vectors[model.labels_ == cluster].sum(axis=0).A[0]\n",
        "        largest = words.argsort()[::-1] # invert sort order\n",
        "        for i in range(0, no_top_words):\n",
        "            size[features[largest[i]]] = abs(words[largest[i]])\n",
        "        wc = WordCloud(background_color=\"white\", max_words=100, width=960, height=540)\n",
        "        wc.generate_from_frequencies(size)\n",
        "        plt.figure(figsize=(12,12))\n",
        "        plt.imshow(wc, interpolation='bilinear')\n",
        "        plt.axis(\"off\")\n",
        "        # if you don't want to save the topic model, comment the next line\n",
        "        plt.savefig(f'cluster{cluster}.png')\n",
        "        plt.close()\n",
        "\n",
        "wordcloud_clusters(kmeans, vectorized_documents, vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "QzT7uVmaM6JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the saved clusters\n",
        "for cluster in range(3):  # Assuming there are 3 clusters\n",
        "    img = plt.imread(f'cluster{cluster}.png')\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f'Cluster {cluster}', fontsize=20)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "cNb7eWIDM6dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot clusters\n",
        "colors = ['blue', 'green', 'purple']\n",
        "cluster = ['notes','name', 'variety'] #You must determine appropriate labels based on the word clouds\n",
        "for i in range(num_clusters):\n",
        "    plt.scatter(reduced_data[kmeans.labels_ == i, 0],\n",
        "                reduced_data[kmeans.labels_ == i, 1],\n",
        "                s=10, color=colors[i],\n",
        "                label=f' {cluster[i]}')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yFcPPiJKPCTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Cluster Label (Atleast one meta-data varibale)\n",
        "cluster_variety_comparison = pd.crosstab(results['cluster'], df['variety'])\n",
        "print(cluster_variety_comparison)\n",
        "\n",
        "# Calculating % distribution of each 'variety' within each cluster\n",
        "percentage_distribution = cluster_variety_comparison.div(cluster_variety_comparison.sum(axis=1), axis=0) * 100\n",
        "print(percentage_distribution)"
      ],
      "metadata": {
        "id": "CFHLhYeSFoox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the optimal # of Clusters\n",
        "from sklearn.metrics import silhouette_score\n",
        "for k in range(2,30):\n",
        "  kmeans = KMeans(n_clusters=k, random_state=10, n_init = 5)\n",
        "  cluster_labels = kmeans.fit_predict(vectorized_documents)\n",
        "  score = silhouette_score(vectorized_documents, cluster_labels)\n",
        "  print(f'The silhouette score for {k} clusters is {score}')"
      ],
      "metadata": {
        "id": "5HMvf9fKIQ3W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}