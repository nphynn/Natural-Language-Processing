{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.util import ngrams\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud\n",
        "import unicodedata\n",
        "import stop_words\n",
        "import spacy\n",
        "from spacy.lang.en import stop_words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "import gensim\n",
        "from gensim.models import LsiModel\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models import CoherenceModel\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "nltk.download('punkt')\n",
        "import gensim\n",
        "from gensim.models import LsiModel\n",
        "import gensim.corpora as corpora\n",
        "from gensim.models import CoherenceModel\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models"
      ],
      "metadata": {
        "id": "s8XKWsezYcWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Load & Preprocess\n",
        "df = pd.read_csv('redditSubmissions.csv', on_bad_lines='warn')\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Normalize encodings\n",
        "df['title'] = df['title'].apply(lambda x: unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore'))\n",
        "\n",
        "# Lower Text\n",
        "df['title'] = df['title'].str.lower()\n",
        "\n",
        "# Remove numbers and punctuation\n",
        "df['title'] = df['title'].str.replace(r'[^\\w\\s]','', regex = True)\n",
        "df['title'] = df['title'].str.replace('\\d+', '', regex=True)\n",
        "\n",
        "# Remove Stopwords\n",
        "stop_words = stop_words.STOP_WORDS\n",
        "df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "OtBfqnlRUBMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of all variables\n",
        "df.describe(include=\"all\").T"
      ],
      "metadata": {
        "id": "_J9NwBmYdFEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Value counts of meta data\n",
        "frequency_table_all = {\n",
        "    'username': df['username'].value_counts(),\n",
        "    'subreddit': df['subreddit'].value_counts(),\n",
        "    'reddit_id': df['reddit_id'].value_counts()\n",
        "}\n",
        "\n",
        "# Print frequency tables\n",
        "for column, table in frequency_table_all.items():\n",
        "    print(f\"Frequency Table for '{column}':\\n\", table, \"\\n\")"
      ],
      "metadata": {
        "id": "oOU2D3VFdNm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary of meta data\n",
        "summary_table_all = {\n",
        "    'username': df['username'].describe(),\n",
        "    'subreddit': df['subreddit'].describe(),\n",
        "    'reddit_id': df['reddit_id'].describe()\n",
        "}\n",
        "\n",
        "for column, summary in summary_table_all.items():\n",
        "    print(f\"Summary for '{column}':\\n\", summary, \"\\n\")"
      ],
      "metadata": {
        "id": "JzJwZPmfdS_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a word cloud of the text.\n",
        "df_reddit = df[df['title'].str.contains(\"funny\")]\n",
        "df1 = df_reddit['title'].str.cat(sep=' ')\n",
        "\n",
        "wc = WordCloud().generate(df1)\n",
        "plt.imshow(wc)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mjBZJwu2dZfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model the data using chosen technique\n",
        "texts = list(df['title'])\n",
        "texts = [word_tokenize(text) for text in texts]\n",
        "\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus, #TDM\n",
        "                                           id2word = dictionary, #Dictionary\n",
        "                                           num_topics = 3,\n",
        "                                           random_state = 100,\n",
        "                                           update_every = 1,\n",
        "                                           chunksize = 100,\n",
        "                                           passes = 10,\n",
        "                                           alpha = 'auto',\n",
        "                                           per_word_topics = True)\n",
        "\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "metadata": {
        "id": "h3kp89yXUBQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print(f'\\nCoherence Score: {coherence_lda}\\nPerplexity Score: {lda_model.log_perplexity(corpus)}')"
      ],
      "metadata": {
        "id": "gdmA04NaVZaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LDA Visualization\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary, n_jobs = 1)\n",
        "pyLDAvis.display(vis)"
      ],
      "metadata": {
        "id": "9M3m0tuNYQLi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}